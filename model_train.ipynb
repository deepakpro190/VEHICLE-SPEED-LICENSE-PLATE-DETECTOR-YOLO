{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2ad398-69e6-4e24-9c99-e7d392a5aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "def convert_xml_to_yolo(xml_file, image_width, image_height):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    with open(xml_file.replace('.xml', '.txt'), 'w') as f:\n",
    "        for obj in root.findall('object'):\n",
    "            name = obj.find('name').text\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(bndbox.find('xmin').text)\n",
    "            ymin = int(bndbox.find('ymin').text)\n",
    "            xmax = int(bndbox.find('xmax').text)\n",
    "            ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "            # Normalize the bounding box coordinates\n",
    "            x_center = (xmin + xmax) / 2 / image_width\n",
    "            y_center = (ymin + ymax) / 2 / image_height\n",
    "            width = (xmax - xmin) / image_width\n",
    "            height = (ymax - ymin) / image_height\n",
    "\n",
    "            # Assuming license plate is class '0'\n",
    "            f.write(f\"0 {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "def process_images(image_folder):\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".JPG\",\".png\",\".PNG\")):\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            xml_path = os.path.join(image_folder, filename.replace(os.path.splitext(filename)[1], \".xml\"))\n",
    "            image=Image.open(image_path)\n",
    "\n",
    "            image_width, image_height = image.size  # Set according to your image size\n",
    "            convert_xml_to_yolo(xml_path, image_width, image_height)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    process_images('dataset/images/', 'dataset/annotations/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5eeb49b-cac3-4518-8cf4-a66f73f48e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images(\"dataset/google_images/\")\n",
    "\n",
    "process_images(\"dataset/video_images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11aadb07-c92a-4fbf-ae98-e8e8c13dad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: AN\n",
      "Folder name: AP\n",
      "Folder name: AR\n",
      "Folder name: AS\n",
      "Folder name: BR\n",
      "Folder name: CG\n",
      "Folder name: CH\n",
      "Folder name: DL\n",
      "Folder name: DN\n",
      "Folder name: GA\n",
      "Folder name: GJ\n",
      "Folder name: HP\n",
      "Folder name: HR\n",
      "Folder name: JH\n",
      "Folder name: JK\n",
      "Folder name: KA\n",
      "Folder name: KL\n",
      "Folder name: LA\n",
      "Folder name: MH\n",
      "Folder name: ML\n",
      "Folder name: MN\n",
      "Folder name: MP\n",
      "Folder name: MZ\n",
      "Folder name: NL\n",
      "Folder name: OD\n",
      "Folder name: PB\n",
      "Folder name: PY\n",
      "Folder name: RJ\n",
      "Folder name: SK\n",
      "Folder name: TN\n",
      "Folder name: TR\n",
      "Folder name: TS\n",
      "Folder name: UK\n",
      "Folder name: UP\n",
      "Folder name: WB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "def iterate_folders(parent_folder):\n",
    "    # Loop through all entries in the parent folder\n",
    "    for folder_name in os.listdir(parent_folder):\n",
    "        # Check if the entry is a directory (folder)\n",
    "        folder_path = os.path.join(parent_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(\"Folder name:\", folder_name)\n",
    "            process_images(pathlib.Path(parent_folder,folder_name))\n",
    "\n",
    "# Example usage\n",
    "parent_folder = 'dataset/State-wise_OLX/'  # Replace with your actual path\n",
    "iterate_folders(parent_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da0913e6-6670-4e49-bbe3-6ba321aba0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = \"dataset/google_images/00b42b2c-f193-4863-b92c-0245cbc816da___3e7fd381-0ae5-4421-8a70-279ee0ec1c61_Nissan-Terrano-Petrol-Review-Images-Black-Front-Angle.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf663c-987f-444f-8573-eaa666949821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the image using PIL\n",
    "image = Image.open(i)\n",
    "\n",
    "# Get image details (size, mode)\n",
    "width, height = image.size\n",
    "print(f\"Image Dimensions: {width}x{height}\")\n",
    "print(f\"Image Mode: {image.mode}\")  # RGB, L, etc.\n",
    "\n",
    "# Display the image\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59791ef9-0df8-474b-b05d-716905fbdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the image using OpenCV (BGR format)\n",
    "image = cv2.imread(i)\n",
    "\n",
    "# Convert to RGB (Matplotlib uses RGB, OpenCV uses BGR)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Get image details (height, width, channels)\n",
    "height, width, channels = image.shape\n",
    "print(f\"Image Dimensions: {height}x{width}\")\n",
    "print(f\"Number of Channels: {channels}\")\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')  # Turn off axis numbers and ticks\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d684ad-788d-46d1-a964-d244dd348e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ YOLO module imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "print(\"✅ YOLO module imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c9a365-1cef-4b2f-a3bc-37ea6941fd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (8.3.94)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (3.7.5)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (2.4.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (0.19.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0466c-389b-4a5f-8e58-1177fbb4413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "print(YOLO('yolov8n.pt'))  # Should print model details if installed correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16463827-7b7e-411e-924a-f3cee54cab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0f3cfd5-64d0-4128-b6e7-abdba89cf31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 5/5 [00:00<00:00, 217.33it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00, 200.01it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 29/29 [00:00<00:00, 375.94it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 8/8 [00:00<00:00, 380.10it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 9/9 [00:00<00:00, 265.94it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 3/3 [00:00<00:00, 230.86it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 19/19 [00:00<00:00, 277.04it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 5/5 [00:00<00:00, 385.87it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 12/12 [00:00<00:00, 387.16it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 4/4 [00:00<00:00, 222.09it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 15/15 [00:00<00:00, 287.52it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 4/4 [00:00<00:00, 266.75it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 8/8 [00:00<00:00, 261.53it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00, 285.49it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 28/28 [00:00<00:00, 447.00it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 7/7 [00:00<00:00, 284.58it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 6/6 [00:00<00:00, 285.61it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00, 285.55it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 10/10 [00:00<00:00, 348.68it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 3/3 [00:00<00:00, 378.37it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 21/21 [00:00<00:00, 335.12it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 6/6 [00:00<00:00, 492.78it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 17/17 [00:00<00:00, 329.45it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 5/5 [00:00<00:00, 384.49it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 17/17 [00:00<00:00, 373.46it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 5/5 [00:00<00:00, 500.05it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 14/14 [00:00<00:00, 337.26it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 4/4 [00:00<00:00, 167.28it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 26/26 [00:00<00:00, 342.09it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 7/7 [00:00<00:00, 268.60it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 16/16 [00:00<00:00, 323.00it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 4/4 [00:00<00:00, 399.62it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 10/10 [00:00<00:00, 391.98it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 3/3 [00:00<00:00, 333.09it/s]\n",
      "Moving files to dataset/split\\train/images: 0it [00:00, ?it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00, 249.97it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 19/19 [00:00<00:00, 324.57it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 5/5 [00:00<00:00, 333.16it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 28/28 [00:00<00:00, 513.14it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 7/7 [00:00<00:00, 736.06it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 4/4 [00:00<00:00, 712.92it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00, 166.71it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 8/8 [00:00<00:00, 241.85it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 3/3 [00:00<00:00, 370.98it/s]\n",
      "Moving files to dataset/split\\train/images: 0it [00:00, ?it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00, 333.52it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 6/6 [00:00<00:00, 326.71it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00, 400.07it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 17/17 [00:00<00:00, 425.06it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 5/5 [00:00<00:00, 416.51it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 21/21 [00:00<00:00, 475.28it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 6/6 [00:00<00:00, 277.02it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 13/13 [00:00<00:00, 313.37it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 4/4 [00:00<00:00, 335.54it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 5/5 [00:00<00:00, 416.84it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00, 200.45it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 10/10 [00:00<00:00, 322.97it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 3/3 [00:00<00:00, 300.26it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 8/8 [00:00<00:00, 444.48it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00, 250.14it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 8/8 [00:00<00:00, 295.46it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00, 328.30it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 12/12 [00:00<00:00, 295.88it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 4/4 [00:00<00:00, 285.56it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████████| 8/8 [00:00<00:00, 347.83it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00, 399.29it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 19/19 [00:00<00:00, 289.55it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 5/5 [00:00<00:00, 312.35it/s]\n",
      "Moving files to dataset/split\\train/images: 100%|█████████████████████████████████████| 20/20 [00:00<00:00, 354.17it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|█████████████████████████████████████████| 5/5 [00:00<00:00, 416.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "def iterate_folders(parent_folder):\n",
    "    # Loop through all entries in the parent folder\n",
    "    for folder_name in os.listdir(parent_folder):\n",
    "        # Check if the entry is a directory (folder)\n",
    "        folder_path = os.path.join(parent_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            dataset_path = pathlib.Path(parent_folder,folder_name) \n",
    "            output_dir = \"dataset/split\"  # Destination for train/val split\n",
    "            train_ratio=0.8\n",
    "            train_img_dir = os.path.join(output_dir, \"train/images\")\n",
    "            train_label_dir = os.path.join(output_dir, \"train/labels\")\n",
    "            val_img_dir = os.path.join(output_dir, \"val/images\")\n",
    "            val_label_dir = os.path.join(output_dir, \"val/labels\")\n",
    "\n",
    "            os.makedirs(train_img_dir, exist_ok=True)\n",
    "            os.makedirs(train_label_dir, exist_ok=True)\n",
    "            os.makedirs(val_img_dir, exist_ok=True)\n",
    "            os.makedirs(val_label_dir, exist_ok=True)\n",
    "            image_extensions = (\".jpg\", \".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\")\n",
    "\n",
    "# Collect image and label pairs\n",
    "            image_files = [f for f in os.listdir(dataset_path) if f.endswith(image_extensions)]\n",
    "            random.shuffle(image_files)  # Shuffle dataset\n",
    "\n",
    "            split_idx = int(len(image_files) * train_ratio)\n",
    "            train_files = image_files[:split_idx]\n",
    "            val_files = image_files[split_idx:]\n",
    "            def move_files(file_list, dest_img_dir, dest_label_dir):\n",
    "                  for file in tqdm(file_list, desc=f\"Moving files to {dest_img_dir}\"):\n",
    "                         img_src = os.path.join(dataset_path, file)\n",
    "                         label_src = os.path.join(dataset_path, file.replace(os.path.splitext(file)[1], \".txt\"))\n",
    "\n",
    "                         img_dest = os.path.join(dest_img_dir, file)\n",
    "                         label_dest = os.path.join(dest_label_dir, file.replace(os.path.splitext(file)[1], \".txt\"))\n",
    "\n",
    "                         shutil.copy(img_src, img_dest)\n",
    "                         if os.path.exists(label_src):  # Copy label only if it exists\n",
    "                             shutil.copy(label_src, label_dest)\n",
    "\n",
    "# Move train and validation files\n",
    "            move_files(train_files, train_img_dir, train_label_dir)\n",
    "            move_files(val_files, val_img_dir, val_label_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "parent_folder = 'dataset/State-wise_OLX/'  # Replace with your actual path\n",
    "iterate_folders(parent_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b185e659-d339-4a34-ab9e-2757aa7d8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset/google_images\"  # Your dataset folder containing images and XML\n",
    "output_dir = \"dataset/split\"  # Destination for train/val split\n",
    "\n",
    "train_ratio = 0.8  # 80% train, 20% validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2370efd4-37ae-499f-84dc-ff8deff26d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = os.path.join(output_dir, \"train/images\")\n",
    "train_label_dir = os.path.join(output_dir, \"train/labels\")\n",
    "val_img_dir = os.path.join(output_dir, \"val/images\")\n",
    "val_label_dir = os.path.join(output_dir, \"val/labels\")\n",
    "\n",
    "os.makedirs(train_img_dir, exist_ok=True)\n",
    "os.makedirs(train_label_dir, exist_ok=True)\n",
    "os.makedirs(val_img_dir, exist_ok=True)\n",
    "os.makedirs(val_label_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfad8556-0c39-4db1-a67c-d9d0ec9aac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_extensions = (\".jpg\", \".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\")\n",
    "\n",
    "# Collect image and label pairs\n",
    "image_files = [f for f in os.listdir(dataset_path) if f.endswith(image_extensions)]\n",
    "random.shuffle(image_files)  # Shuffle dataset\n",
    "\n",
    "split_idx = int(len(image_files) * train_ratio)\n",
    "train_files = image_files[:split_idx]\n",
    "val_files = image_files[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56041846-7aab-43b0-9704-ddf26510f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving files to dataset/split\\train/images: 100%|███████████████████████████████████| 353/353 [00:01<00:00, 256.73it/s]\n",
      "Moving files to dataset/split\\val/images: 100%|███████████████████████████████████████| 89/89 [00:00<00:00, 291.11it/s]\n"
     ]
    }
   ],
   "source": [
    "def move_files(file_list, dest_img_dir, dest_label_dir):\n",
    "    for file in tqdm(file_list, desc=f\"Moving files to {dest_img_dir}\"):\n",
    "        img_src = os.path.join(dataset_path, file)\n",
    "        label_src = os.path.join(dataset_path, file.replace(os.path.splitext(file)[1], \".txt\"))\n",
    "\n",
    "        img_dest = os.path.join(dest_img_dir, file)\n",
    "        label_dest = os.path.join(dest_label_dir, file.replace(os.path.splitext(file)[1], \".txt\"))\n",
    "\n",
    "        shutil.copy(img_src, img_dest)\n",
    "        if os.path.exists(label_src):  # Copy label only if it exists\n",
    "            shutil.copy(label_src, label_dest)\n",
    "\n",
    "# Move train and validation files\n",
    "move_files(train_files, train_img_dir, train_label_dir)\n",
    "move_files(val_files, val_img_dir, val_label_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e87897c-7c00-4472-b453-60d8eb023b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b076ef79-4a48-48ee-9280-95a7dccfcfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MOVED ORIGINAL DATSSETS FILE FROM DATASET TO ORIGINAL_DATASET TO HAVE CORREC STRUCTURE FOR DATASET FOLDER HAVINHG FILES FOR TRAIN-VAL'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''MOVED ORIGINAL DATSSETS FILE FROM DATASET TO ORIGINAL_DATASET TO HAVE CORREC STRUCTURE FOR DATASET FOLDER HAVINHG FILES FOR TRAIN-VAL'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b96f65-dfdf-4151-8b7e-ef829699edb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (1.4.18)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (8.0.114)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from albumentations) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from albumentations) (1.10.1)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from albumentations) (0.21.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from albumentations) (2.10.6)\n",
      "Requirement already satisfied: albucore==0.0.17 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from albumentations) (0.0.17)\n",
      "Requirement already satisfied: eval-type-backport in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from albumentations) (0.2.2)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from albumentations) (4.11.0.86)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from albumentations) (4.12.2)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (3.7.5)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (2.4.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (0.19.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib>=3.2.2->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (3.1)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from scikit-image>=0.21.0->albumentations) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from torch>=1.7.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from torch>=1.7.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from torch>=1.7.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from torch>=1.7.0->ultralytics) (2024.12.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->ultralytics) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations ultralytics opencv-python tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00cc76f-8c65-4c77-a486-6ad5344efb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e29c0-d55f-4cc7-9915-acd2274fee4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0155642c-6962-48e7-bd78-d8bc96a13bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation error for dataset/split/train/images/HP20.jpg, iteration 0: Expected y_max for bbox [0.16176471 0.9444444  0.36029413 1.0555556  0.        ] to be in the range [0.0, 1.0], got 1.0555555820465088.\n",
      "Bounding boxes: [[0.2610294117647059, 1.0, 0.19852941176470587, 0.1111111111111111]]\n",
      "Augmentation error for dataset/split/train/images/HP20.jpg, iteration 1: Expected y_max for bbox [0.16176471 0.9444444  0.36029413 1.0555556  0.        ] to be in the range [0.0, 1.0], got 1.0555555820465088.\n",
      "Bounding boxes: [[0.2610294117647059, 1.0, 0.19852941176470587, 0.1111111111111111]]\n",
      "Augmentation error for dataset/split/train/images/HP20.jpg, iteration 2: Expected y_max for bbox [0.16176471 0.9444444  0.36029413 1.0555556  0.        ] to be in the range [0.0, 1.0], got 1.0555555820465088.\n",
      "Bounding boxes: [[0.2610294117647059, 1.0, 0.19852941176470587, 0.1111111111111111]]\n",
      "Augmentation error for dataset/split/train/images/HP20.jpg, iteration 3: Expected y_max for bbox [0.16176471 0.9444444  0.36029413 1.0555556  0.        ] to be in the range [0.0, 1.0], got 1.0555555820465088.\n",
      "Bounding boxes: [[0.2610294117647059, 1.0, 0.19852941176470587, 0.1111111111111111]]\n",
      "Augmentation error for dataset/split/train/images/HP20.jpg, iteration 4: Expected y_max for bbox [0.16176471 0.9444444  0.36029413 1.0555556  0.        ] to be in the range [0.0, 1.0], got 1.0555555820465088.\n",
      "Bounding boxes: [[0.2610294117647059, 1.0, 0.19852941176470587, 0.1111111111111111]]\n",
      "Augmentation error for dataset/split/train/images/HP20.jpg, iteration 5: Expected y_max for bbox [0.16176471 0.9444444  0.36029413 1.0555556  0.        ] to be in the range [0.0, 1.0], got 1.0555555820465088.\n",
      "Bounding boxes: [[0.2610294117647059, 1.0, 0.19852941176470587, 0.1111111111111111]]\n",
      "Augmentation error for dataset/split/train/images/HP20.jpg, iteration 6: Expected y_max for bbox [0.16176471 0.9444444  0.36029413 1.0555556  0.        ] to be in the range [0.0, 1.0], got 1.0555555820465088.\n",
      "Bounding boxes: [[0.2610294117647059, 1.0, 0.19852941176470587, 0.1111111111111111]]\n",
      "Augmentation error for dataset/split/train/images/HP20.jpg, iteration 7: Expected y_max for bbox [0.16176471 0.9444444  0.36029413 1.0555556  0.        ] to be in the range [0.0, 1.0], got 1.0555555820465088.\n",
      "Bounding boxes: [[0.2610294117647059, 1.0, 0.19852941176470587, 0.1111111111111111]]\n",
      "Augmentation completed! ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define Augmentation Pipeline\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "    A.CLAHE(p=0.1),\n",
    "], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"]))\n",
    "\n",
    "\n",
    "def read_yolo_annotations(label_path):\n",
    "    \"\"\"Reads YOLO annotations and returns bounding boxes & class labels (normalized).\"\"\"\n",
    "    boxes, class_labels = [], []\n",
    "    try:\n",
    "        with open(label_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            if not lines:\n",
    "                print(f\"Warning: {label_path} is empty. Skipping.\")\n",
    "                return [], []\n",
    "\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 5:  # Ensure valid YOLO format\n",
    "                    print(f\"Invalid annotation in {label_path}: {line}\")\n",
    "                    continue\n",
    "\n",
    "                class_id = int(parts[0])\n",
    "                bbox = list(map(float, parts[1:]))  # Normalized [x_center, y_center, width, height]\n",
    "                boxes.append(bbox)\n",
    "                class_labels.append(class_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {label_path}: {e}\")\n",
    "    return boxes, class_labels\n",
    "\n",
    "\n",
    "def write_yolo_annotations(output_path, boxes, class_labels):\n",
    "    \"\"\"Writes augmented YOLO annotations (already normalized).\"\"\"\n",
    "    try:\n",
    "        with open(output_path, \"w\") as file:\n",
    "            for cls, bbox in zip(class_labels, boxes):\n",
    "                file.write(f\"{cls} {' '.join(map(str, bbox))}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing {output_path}: {e}\")\n",
    "\n",
    "\n",
    "def clip_bboxes(bboxes):\n",
    "    \"\"\"Clips bounding box coordinates to ensure they are in the range [0, 1].\"\"\"\n",
    "    clipped_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x, y, w, h = bbox\n",
    "\n",
    "        # Ensure values are within the valid range\n",
    "        x = np.clip(x, 0, 1)\n",
    "        y = np.clip(y, 0, 1)\n",
    "        w = np.clip(w, 0, 1)\n",
    "        h = np.clip(h, 0, 1)\n",
    "\n",
    "        # Skip invalid boxes\n",
    "        if w == 0 or h == 0:\n",
    "            print(f\"Skipping invalid bbox: {bbox}\")\n",
    "            continue\n",
    "\n",
    "        clipped_bboxes.append([x, y, w, h])\n",
    "    return clipped_bboxes\n",
    "\n",
    "\n",
    "def augment_image(image_path, label_path, output_folder, num_augmentations=8):\n",
    "    \"\"\"Applies multiple augmentations per image and saves the results.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Warning: Failed to load image {image_path}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Read YOLO annotations\n",
    "    boxes, class_labels = read_yolo_annotations(label_path)\n",
    "    if not boxes:\n",
    "        print(f\"Skipping {image_path} due to missing or invalid bounding boxes.\")\n",
    "        return\n",
    "\n",
    "    clipped_boxes = clip_bboxes(boxes)\n",
    "\n",
    "    for i in range(num_augmentations):\n",
    "        try:\n",
    "            augmented = transform(image=image, bboxes=clipped_boxes, class_labels=class_labels)\n",
    "            aug_bboxes = augmented[\"bboxes\"]\n",
    "\n",
    "            # Skip augmentation if bounding boxes are missing after transformation\n",
    "            if not aug_bboxes:\n",
    "                print(f\"Skipping augmentation {i} for {image_path} due to bbox issue.\")\n",
    "                continue\n",
    "\n",
    "            # Save augmented image\n",
    "            aug_img_name = os.path.basename(image_path).replace(\".jpg\", f\"_aug{i}.jpg\")\n",
    "            cv2.imwrite(os.path.join(output_folder, aug_img_name), augmented[\"image\"])\n",
    "\n",
    "            # Save new annotations\n",
    "            aug_label_name = os.path.basename(label_path).replace(\".txt\", f\"_aug{i}.txt\")\n",
    "            write_yolo_annotations(os.path.join(output_folder, aug_label_name), aug_bboxes, class_labels)\n",
    "\n",
    "        except ValueError as v:\n",
    "            print(f\"Augmentation error for {image_path}, iteration {i}: {v}\")\n",
    "            print(f\"Bounding boxes: {clipped_boxes}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "# Directory Paths\n",
    "image_folder = \"dataset/split/train/images/\"\n",
    "label_folder = \"dataset/split/train/labels/\"\n",
    "output_folder = \"dataset/split/augmented/\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define supported image extensions\n",
    "image_extensions = (\".jpg\", \".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\")\n",
    "\n",
    "# Collect image and label pairs\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith(image_extensions)]\n",
    "\n",
    "# Process All Images\n",
    "for idx, image_file in enumerate(image_files):\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    label_path = os.path.join(label_folder, image_file.rsplit('.', 1)[0] + \".txt\")\n",
    "   \n",
    "    if os.path.exists(label_path):\n",
    "        augment_image(image_path, label_path, output_folder)\n",
    "    else:\n",
    "        print(f\"Warning: No label file found for {image_file}. Skipping.\")\n",
    "\n",
    "print(\"Augmentation completed! ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe916785-ac86-4e6a-9ec2-5d80f1906e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "365df9a1-fab8-4690-a1d5-3d538c2f7644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89821670-83c4-4f2d-bbb1-082514680362",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=Path(\"dataset\")\n",
    "data_yaml_path=dataset_path/\"data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26ade7e3-8755-4858-86a5-96817687c175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset setup completed!\n"
     ]
    }
   ],
   "source": [
    "# Write data.yaml\n",
    "if not data_yaml_path.exists():\n",
    "    data_yaml = {\n",
    "        \"train\": str(dataset_path / \"images/train\"),\n",
    "        \"val\": str(dataset_path / \"images/val\"),\n",
    "        \"nc\": 1,  # Number of classes\n",
    "        \"names\": [\"plate\"]  # Change according to your dataset\n",
    "    }\n",
    "    with open(data_yaml_path, \"w\") as f:\n",
    "        yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "        \n",
    "print(\"✅ Dataset setup completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4474a396-9103-4805-aa2f-7e06ae21df0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "GPU Count: 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA Available:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU Count:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent Device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU Name:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo GPU found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\vlpr-env\\lib\\site-packages\\torch\\cuda\\__init__.py:878\u001b[0m, in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\vlpr-env\\lib\\site-packages\\torch\\cuda\\__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m     )\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Count:\", torch.cuda.device_count())\n",
    "print(\"Current Device:\", torch.cuda.current_device())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16764182-6781-4cd2-8786-40a3df717413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.device_count())  # Should show number of GPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f2da8d-c405-48dc-922a-b264e013b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529e84f-00b8-4586-baa6-182051991b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e38277d-8c83-41e0-a3cf-5fbcdaf726eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:511: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "New https://pypi.org/project/ultralytics/8.3.70 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.114  Python-3.8.20 torch-2.4.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=100, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=trained1, exist_ok=False, pretrained=yolov8n.pt, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\trained12\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "C:\\Users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:511: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "C:\\Users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages\\ultralytics\\yolo\\utils\\checks.py:369: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "C:\\Users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py:223: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\dell\\projects\\vehicle_license\\dataset\\labels\\train.cache... 8424 images, 1382 backgrounds, 0 c\u001b[0m\n",
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python38\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.2 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python38\\site-packages\\albumentations\\core\\composition.py:192: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\dell\\projects\\vehicle_license\\dataset\\labels\\val.cache... 354 images, 0 backgrounds, 0 corrupt: \u001b[0m\n",
      "Plotting labels to runs\\detect\\trained12\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\trained12\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/1226 [00:00<?, ?it/s]C:\\Users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py:328: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "      1/100      1.13G      1.026      1.672      1.034         14        640: 100%|██████████| 1226/1226 [07:49<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:11\n",
      "                   all        354        354       0.96      0.887      0.966      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      1.18G       1.01     0.9214      1.009         11        640: 100%|██████████| 1226/1226 [05:50<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:12\n",
      "                   all        354        354       0.98      0.967      0.989      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      1.18G      1.044     0.8336      1.044         10        640: 100%|██████████| 1226/1226 [03:25<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:06\n",
      "                   all        354        354      0.934       0.91      0.962       0.72\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      1.17G       1.04     0.7991      1.055         12        640: 100%|██████████| 1226/1226 [02:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:07\n",
      "                   all        354        354       0.96      0.938      0.978      0.751\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      1.14G      1.006     0.7375      1.045         12        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.974      0.957      0.981       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100      1.13G     0.9648     0.6858      1.023         12        640: 100%|██████████| 1226/1226 [02:52<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:07\n",
      "                   all        354        354      0.935      0.895      0.958      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      1.14G     0.9468     0.6582      1.018         10        640: 100%|██████████| 1226/1226 [02:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.982      0.887      0.961      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      1.14G      0.922     0.6318       1.01         12        640: 100%|██████████| 1226/1226 [02:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354       0.93      0.895      0.956      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      1.14G     0.9056     0.6173      1.005          6        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:06\n",
      "                   all        354        354      0.937      0.949      0.981      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100      1.13G     0.8921     0.5945     0.9998          7        640: 100%|██████████| 1226/1226 [02:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.966      0.881      0.952      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100      1.13G     0.8842     0.5682     0.9929          6        640: 100%|██████████| 1226/1226 [02:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:06\n",
      "                   all        354        354      0.965      0.918       0.98      0.809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100      1.14G     0.8679     0.5656     0.9826          5        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.962       0.93       0.98      0.808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100      1.14G     0.8633     0.5542     0.9856         10        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354       0.95      0.879      0.953      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100      1.13G      0.852     0.5429     0.9795          7        640: 100%|██████████| 1226/1226 [02:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:09\n",
      "                   all        354        354      0.972      0.879      0.943      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100      1.13G     0.8452     0.5297     0.9732         11        640: 100%|██████████| 1226/1226 [02:55<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354       0.97      0.899      0.973      0.818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100      1.13G     0.8397     0.5207     0.9716          9        640: 100%|██████████| 1226/1226 [02:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.979      0.902      0.979      0.834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100      1.13G      0.834     0.5141     0.9707          9        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:06\n",
      "                   all        354        354      0.977      0.844      0.904      0.768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      1.13G     0.8277     0.5111     0.9698          9        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.971      0.864      0.922      0.759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100      1.13G     0.8272     0.5025      0.961         11        640: 100%|██████████| 1226/1226 [05:47<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10\n",
      "                   all        354        354      0.983      0.887      0.969      0.822\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100      1.13G     0.8144     0.4904     0.9614         11        640: 100%|██████████| 1226/1226 [06:52<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:08\n",
      "                   all        354        354      0.984      0.859      0.961      0.808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      1.13G     0.8128     0.4916     0.9609         11        640: 100%|██████████| 1226/1226 [06:15<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:08\n",
      "                   all        354        354       0.99      0.847      0.941      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      1.13G     0.7992     0.4859     0.9547          9        640: 100%|██████████| 1226/1226 [07:56<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:09\n",
      "                   all        354        354      0.984      0.871      0.953      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100      1.13G     0.8014     0.4819     0.9541         12        640: 100%|██████████| 1226/1226 [09:11<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:12\n",
      "                   all        354        354      0.972      0.876      0.957      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100      1.13G     0.7916     0.4737     0.9497          8        640: 100%|██████████| 1226/1226 [11:17<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:07\n",
      "                   all        354        354      0.967      0.879      0.955       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100      1.13G     0.7903     0.4674     0.9499          9        640: 100%|██████████| 1226/1226 [03:06<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.958      0.887      0.959      0.823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100      1.13G     0.7759     0.4574     0.9416         10        640: 100%|██████████| 1226/1226 [03:02<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.973      0.879      0.959      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      1.14G     0.7747     0.4604     0.9445          9        640: 100%|██████████| 1226/1226 [03:02<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.987      0.875      0.941      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      1.14G     0.7773     0.4567     0.9444          8        640: 100%|██████████| 1226/1226 [03:02<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.967      0.856      0.945       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      1.14G     0.7656     0.4477      0.943         11        640: 100%|██████████| 1226/1226 [03:02<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.992      0.856      0.935      0.804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100      1.13G     0.7593     0.4435     0.9378          9        640: 100%|██████████| 1226/1226 [03:02<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.987      0.869      0.941      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100      1.14G     0.7591     0.4408     0.9371         10        640: 100%|██████████| 1226/1226 [03:02<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.975      0.859      0.944      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100      1.14G     0.7516     0.4399     0.9353         10        640: 100%|██████████| 1226/1226 [03:02<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.976      0.884      0.949      0.818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100      1.14G     0.7624     0.4363     0.9392          6        640: 100%|██████████| 1226/1226 [02:45<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.975      0.878      0.943      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100      1.13G     0.7441     0.4371     0.9301          9        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.978      0.864      0.936      0.808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100      1.13G     0.7455     0.4291     0.9345          9        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.984      0.867      0.934      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100      1.14G     0.7398     0.4261     0.9321         12        640: 100%|██████████| 1226/1226 [02:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354       0.99      0.862      0.931      0.804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100      1.13G     0.7363     0.4229     0.9258         13        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.993      0.852      0.927      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100      1.13G     0.7354     0.4193     0.9294          4        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.982      0.862      0.929      0.804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100      1.13G     0.7259     0.4187     0.9258          7        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354       0.99      0.853      0.924      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100      1.13G     0.7225     0.4149     0.9238          9        640: 100%|██████████| 1226/1226 [02:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:06\n",
      "                   all        354        354      0.992      0.867      0.942      0.814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100      1.13G     0.7198     0.4135     0.9248         12        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.984      0.848      0.923      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100      1.13G      0.715     0.4071     0.9213          9        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.984      0.851       0.92      0.795\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100      1.13G       0.72     0.4056      0.925         11        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.984      0.852      0.922      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100      1.13G     0.7047     0.4011     0.9157          8        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.986      0.853      0.916      0.797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100      1.13G     0.7041     0.4012     0.9168         12        640: 100%|██████████| 1226/1226 [02:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.987      0.859       0.92      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100      1.13G      0.696      0.389     0.9126          8        640: 100%|██████████| 1226/1226 [02:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.983      0.864      0.936      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100      1.14G     0.6973     0.3935      0.914          9        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.995      0.836      0.931      0.809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100      1.13G     0.7002     0.3912     0.9155         15        640: 100%|██████████| 1226/1226 [02:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.993      0.853      0.928        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100      1.14G     0.6951     0.3879     0.9143         16        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.996      0.845      0.925      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100      1.13G     0.6907     0.3842     0.9101         12        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.987      0.847      0.917      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100      1.13G     0.6807     0.3851     0.9091         13        640: 100%|██████████| 1226/1226 [02:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.988      0.839      0.922      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/100      1.14G     0.6789     0.3805     0.9074         12        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.981      0.857      0.934      0.804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/100      1.13G     0.6763     0.3825     0.9053         13        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354       0.99      0.852      0.929      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/100      1.13G     0.6709     0.3736     0.9049          9        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.987      0.855      0.919      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/100      1.13G     0.6691     0.3701     0.9036         13        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354       0.99       0.85      0.917      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/100      1.13G     0.6658     0.3705     0.9008         10        640: 100%|██████████| 1226/1226 [02:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.989      0.845       0.92      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/100      1.13G      0.659     0.3654     0.9012          9        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.993      0.853      0.921      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/100      1.13G     0.6567     0.3615     0.9032         10        640: 100%|██████████| 1226/1226 [02:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.974      0.853      0.921        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/100      1.13G     0.6536     0.3605     0.9003          9        640: 100%|██████████| 1226/1226 [02:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354       0.99      0.848      0.926      0.804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/100      1.13G      0.656     0.3595     0.9004         10        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.996      0.842       0.93      0.809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/100      1.13G     0.6552      0.359     0.9014          6        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.993      0.842      0.929      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/100      1.13G     0.6459      0.357     0.8959         10        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.993      0.836      0.924      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/100      1.13G     0.6445     0.3505     0.8971          8        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.993      0.841       0.92      0.797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/100      1.14G     0.6353     0.3475     0.8929          5        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.993      0.839      0.922      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/100      1.13G     0.6287     0.3438     0.8903          9        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:05\n",
      "                   all        354        354      0.984      0.845      0.925      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/100      1.13G     0.6343     0.3437     0.8939         12        640: 100%|██████████| 1226/1226 [02:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:06\n",
      "                   all        354        354      0.991      0.842      0.923      0.798\n",
      "Stopping training early as no improvement observed in last 50 epochs. Best results observed at epoch 16, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "66 epochs completed in 3.800 hours.\n",
      "C:\\Users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages\\ultralytics\\yolo\\utils\\torch_utils.py:388: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from runs\\detect\\trained12\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\trained12\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\trained12\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.114  Python-3.8.20 torch-2.4.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "C:\\Users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:511: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:06\n",
      "                   all        354        354      0.979      0.902      0.979      0.833\n",
      "Speed: 0.3ms preprocess, 3.7ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\trained12\u001b[0m\n",
      "C:\\Users\\dell\\anaconda3\\envs\\vlpr-env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:511: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "\n",
    "# Initialize the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # You can change to another pre-trained model if needed\n",
    "\n",
    "# Start training\n",
    "model.train(\n",
    "    imgsz=640,  # Correct argument for image size\n",
    "    batch=8,   # Correct argument for batch size\n",
    "    epochs=100,\n",
    "    data=\"data.yaml\",\n",
    "    pretrained='yolov8n.pt',\n",
    "    device=0,  # Dynamically set the device to 'cuda' or 'cpu'\n",
    "    save=True,\n",
    "    name=\"trained1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca95cd-b153-4bd4-b1a0-8b85f3714187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is enabled\n",
    "\n",
    "!python -c \"import torchvision; print(torchvision.__version__)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0037378-ea32-4ad7-a534-6f9fa1e6c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "print(torchvision.__version__)\n",
    "\n",
    "# Check if torchvision has NMS\n",
    "try:\n",
    "    from torchvision.ops import nms\n",
    "    print(\"NMS is available in torchvision.\")\n",
    "except ImportError:\n",
    "    print(\"NMS is NOT available in torchvision.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043fce0-0f22-43ff-bfdd-e765eceb7fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2d8c38-fbcb-4466-b6bd-df1786ce06b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total RAM: 16.85 GB\n",
      "Available RAM: 7.02 GB\n",
      "Used RAM: 9.83 GB\n",
      "RAM Usage: 58.4%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "ram = psutil.virtual_memory()\n",
    "print(f\"Total RAM: {ram.total / 1e9:.2f} GB\")\n",
    "print(f\"Available RAM: {ram.available / 1e9:.2f} GB\")\n",
    "print(f\"Used RAM: {ram.used / 1e9:.2f} GB\")\n",
    "print(f\"RAM Usage: {ram.percent}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35059600-7d16-462c-a70d-aa19923e1850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter is using: 0.44 GB of RAM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psutil\n",
    "\n",
    "pid = os.getpid()  # Get current Jupyter Notebook process ID\n",
    "memory_usage = psutil.Process(pid).memory_info().rss / 1e9  # Convert to GB\n",
    "print(f\"Jupyter is using: {memory_usage:.2f} GB of RAM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1a30f67-9d14-4012-a2bc-1529ea57f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# Collect garbage to free up memory\n",
    "gc.collect()\n",
    "\n",
    "# If using GPU, clear the cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()  # This line is GPU-specific, can be omitted for CPU\n",
    "\n",
    "# Optional: Reset memory cache if you're using PyTorch and running on CPU\n",
    "torch.cuda.empty_cache()  # Clears the PyTorch cache for both GPU and CPU if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20299b1b-7919-45df-9640-eb685dc857be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Number of devices: 1\n",
      "CUDA Device 0: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. Number of devices: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # Check the name of each device and its corresponding index (0, 1, etc.)\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"CUDA Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c7f68-4736-4013-884a-62c65e9998cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
